{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from DroneEnv import DroneEnvClass\n",
    "import math\n",
    "import collections\n",
    "import random\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque(maxlen = 500)\n",
    "        self.minibatch_size = 16\n",
    "\n",
    "    def append(self, state, reward, next_state, terminal):\n",
    "        self.buffer.append([state, reward, next_state, terminal])\n",
    "\n",
    "    def sample(self):\n",
    "        mini_batch = random.sample(self.buffer, self.minibatch_size)\n",
    "        s_lst, r_lst, s_prime_lst, done_mask_lst = map(list, zip(*mini_batch))\n",
    "        return torch.FloatTensor(s_lst).to(device), torch.FloatTensor(r_lst).to(device), \\\n",
    "                torch.FloatTensor(s_prime_lst).to(device), torch.FloatTensor(done_mask_lst).to(device)\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Actor, self).__init__()\n",
    "        self.actionNetwork = nn.Sequential(\n",
    "            nn.Linear(12, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128,4)\n",
    "        )\n",
    "        \n",
    "    def forward(self, state):\n",
    "        state = torch.FloatTensor(state).view(-1,state.shape[-1])\n",
    "        return torch.sigmoid(self.actionNetwork(state))\n",
    "    \n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.valueNetwork = nn.Sequential(\n",
    "            nn.Linear(12+4, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128,1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, state, qValue):\n",
    "        state = torch.FloatTensor(state).view(-1,state.shape[-1])\n",
    "        qValue = torch.FloatTensor(qValue).view(-1,qValue.shape[-1])\n",
    "        return self.valueNetwork(torch.cat([state, qValue], dim = -1))\n",
    "\n",
    "\n",
    "\n",
    "class DDPG():\n",
    "    def __init__(self):\n",
    "        super(DDPG, self).__init__()\n",
    "        self.actor = Actor()\n",
    "        self.actor_target = Actor()\n",
    "        self.critic = Critic()\n",
    "        self.critic_target = Critic()\n",
    "        self.actionOptimizer = optim.Adam(self.actor.parameters(), lr = 0.01)\n",
    "        self.valueOptimizer = optim.Adam(self.critic.parameters(), lr = 0.01)\n",
    "        self.env = DroneEnvClass()\n",
    "        self.total_reward = 0\n",
    "        self.tau = 0.001\n",
    "        self.gamma = 0.9\n",
    "        self.last_state = None\n",
    "        self.last_action = None\n",
    "        self.flag = False\n",
    "        \n",
    "    def train(self, epi):\n",
    "        self.last_state = self.env.reset()\n",
    "        while True:\n",
    "            #print('state :', self.last_state)\n",
    "            print('height :', self.last_state[-1])\n",
    "            last_w = self.actor.actionNetwork[-1].weight\n",
    "            \n",
    "            self.actor.eval()\n",
    "            action = self.actor(self.last_state)\n",
    "            print('action :',action)\n",
    "            state, reward, done= self.env.step(action[0])\n",
    "            \n",
    "            self.total_reward += reward\n",
    "            #self.replay_buffer.append(self.last_state, reward, state, done)\n",
    "            '''\n",
    "            self.env.client.simPause(True)\n",
    "            if self.replay_buffer.size()>self.replay_buffer.minibatch_size:\n",
    "                print('actions : ', action, 'q : ', self.last_q)\n",
    "                for _ in range(self.num_replay):\n",
    "                    self.optimize_network(self.agent)\n",
    "            else:\n",
    "                print('batxh_size : ', self.replay_buffer.size(), 'actions : ', action)\n",
    "            self.env.client.simPause(False)\n",
    "            '''\n",
    "            self.actor.train()\n",
    "            q_next_mat = self.critic_target(state, self.actor_target(state))\n",
    "            targetQ = reward + q_next_mat*(1-done)*self.gamma\n",
    "            \n",
    "            self.valueOptimizer.zero_grad()\n",
    "            q_mat = self.critic(self.last_state, action.detach())\n",
    "            valueLoss = F.smooth_l1_loss(q_mat,targetQ)\n",
    "            valueLoss.backward()\n",
    "            self.valueOptimizer.step()\n",
    "            \n",
    "            self.actionOptimizer.zero_grad()\n",
    "            q_mat = self.critic(state, self.actor(state))\n",
    "            actionLoss = (-q_mat).backward()\n",
    "            self.actionOptimizer.step()\n",
    "            w = self.actor.actionNetwork[-1].weight\n",
    "            \n",
    "            self.soft_update(self.critic, self.critic_target, self.tau)\n",
    "            self.soft_update(self.actor, self.actor_target, self.tau)        \n",
    "            #print(last_w)\n",
    "            #print(w)\n",
    "            if done:\n",
    "                break\n",
    "            self.last_state = state\n",
    "        if(False):\n",
    "            print('#episode : ',epi, 'avg_reward : ', self.total_reward/10, 'batch_size : ', self.replay_buffer.size())\n",
    "            self.total_reward = 0\n",
    "            \n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "            \n",
    "    def optimize_network(self, agent):\n",
    "        states, rewards, next_states, terminals = self.replay_buffer.sample()\n",
    "        \n",
    "        q_next_mat, _ = agent.qValue(next_states)\n",
    "        v_next_vec = q_next_mat*(1-terminals.view(-1,1))\n",
    "        target_vec = rewards.view(-1,1) + v_next_vec\n",
    "        \n",
    "        q_mat, _ = agent.qValue(states)\n",
    "        loss = F.smooth_l1_loss(q_mat,target_vec)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n",
      "Client Ver:1 (Min Req: 1), Server Ver:1 (Min Req: 1)\n",
      "\n",
      "Connected!\n",
      "Client Ver:1 (Min Req: 1), Server Ver:1 (Min Req: 1)\n",
      "\n",
      "height : -0.14649657905101776\n",
      "action : tensor([[0.4800, 0.5047, 0.4819, 0.5254]], grad_fn=<SigmoidBackward>)\n",
      "height : -0.08581556379795074\n",
      "action : tensor([[0.5985, 0.3676, 0.6957, 0.6878]], grad_fn=<SigmoidBackward>)\n",
      "height : -0.01787920668721199\n",
      "action : tensor([[0.9802, 0.0197, 0.9995, 0.9999]], grad_fn=<SigmoidBackward>)\n",
      "height : 0.04369944706559181\n",
      "action : tensor([[1.0000e+00, 3.3132e-18, 1.0000e+00, 1.0000e+00]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "height : 0.1488141566514969\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 0.4242457151412964\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 0.7864145040512085\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 1.2540855407714844\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 1.816831111907959\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 2.464207410812378\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 3.1958019733428955\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 4.005411624908447\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 4.885741710662842\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 5.827207565307617\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 6.827646255493164\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 7.879746437072754\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 8.979942321777344\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 10.124090194702148\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 11.308158874511719\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 12.5289888381958\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 13.819217681884766\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 15.10891056060791\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 16.478776931762695\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 17.92467498779297\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 19.436447143554688\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 20.971303939819336\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 22.5174617767334\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 24.116065979003906\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 25.731273651123047\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "Connected!\n",
      "Client Ver:1 (Min Req: 1), Server Ver:1 (Min Req: 1)\n",
      "\n",
      "height : -0.14649657905101776\n",
      "action : tensor([[9.9945e-01, 5.2138e-04, 9.9989e-01, 9.9997e-01]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "height : -0.14473314583301544\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : -0.13304580748081207\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 0.040778934955596924\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 0.3134133815765381\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 0.6881864666938782\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 1.1637020111083984\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 1.7323731184005737\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 2.3842413425445557\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 3.118596315383911\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 3.92462420463562\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 4.799531936645508\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 5.736342906951904\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 6.728640079498291\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 7.769845008850098\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 8.857843399047852\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 9.988656044006348\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 11.158553123474121\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 12.364370346069336\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 13.600473403930664\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 14.898824691772461\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 16.25603675842285\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 17.68675422668457\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 19.242528915405273\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 20.834558486938477\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 22.503217697143555\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 24.248313903808594\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "Connected!\n",
      "Client Ver:1 (Min Req: 1), Server Ver:1 (Min Req: 1)\n",
      "\n",
      "height : -0.14649657905101776\n",
      "action : tensor([[9.9984e-01, 1.4975e-04, 9.9997e-01, 9.9999e-01]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "height : -0.14473478496074677\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : -0.13300871849060059\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 0.04089312255382538\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 0.3041759133338928\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 0.6765449047088623\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 1.1495903730392456\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 1.7158291339874268\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 2.3652758598327637\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 3.098076820373535\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 3.9024124145507812\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 4.775789260864258\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 5.711672782897949\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 6.732664108276367\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 7.776600360870361\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 8.86649227142334\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 10.03271770477295\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 11.206320762634277\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 12.41561508178711\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 13.692061424255371\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 14.963271141052246\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 16.29488182067871\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 17.612672805786133\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 18.96025276184082\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 20.32306480407715\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 21.70546531677246\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 23.087190628051758\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 24.476926803588867\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 25.870710372924805\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "Connected!\n",
      "Client Ver:1 (Min Req: 1), Server Ver:1 (Min Req: 1)\n",
      "\n",
      "height : -0.14649657905101776\n",
      "action : tensor([[9.9986e-01, 1.3534e-04, 9.9998e-01, 9.9999e-01]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "height : -0.14473485946655273\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : -0.13300727307796478\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 0.04089755192399025\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 0.3041820824146271\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 0.6765522956848145\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 1.164524793624878\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 1.7329357862472534\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 2.4041237831115723\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 3.1420416831970215\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 3.9504005908966064\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 4.853484630584717\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 5.794422149658203\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 6.7894110679626465\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 7.83460807800293\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 8.925665855407715\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 10.059361457824707\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 11.265549659729004\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 12.475325584411621\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 13.710219383239746\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 14.96959114074707\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 16.276777267456055\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 17.617860794067383\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 19.00170135498047\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 20.44436264038086\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 21.956218719482422\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 23.529232025146484\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 25.16557502746582\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 26.868587493896484\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 28.635343551635742\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 30.43914222717285\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 32.23892593383789\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 34.04084777832031\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 35.880550384521484\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 37.8183479309082\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 39.7086296081543\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 41.599708557128906\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 43.36474609375\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 45.026432037353516\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 46.638092041015625\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 48.213382720947266\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 49.77180099487305\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 51.36960220336914\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 52.92164993286133\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 54.52751541137695\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 56.17451858520508\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "height : 57.80018997192383\n",
      "action : tensor([[1., 0., 1., 1.]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = DDPG()\n",
    "\n",
    "for epi in range(1000):\n",
    "    model.train(epi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.from_numpy(np.array([1,2,3]))\n",
    "b = torch.Tensor(np.array([[1],[2],[3]]))\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 9.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a*torch.squeeze(b,1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
